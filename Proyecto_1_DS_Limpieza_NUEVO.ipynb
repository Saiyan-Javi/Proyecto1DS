{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "031a572f",
   "metadata": {},
   "source": [
    "# Proyecto 1 – Limpieza (Archivo NUEVO)\n",
    "**Fuente**: `/mnt/data/establecimientos_diversificado_raw_concat.csv`\n",
    "\n",
    "Este cuaderno realiza **exclusivamente limpieza** y deja la trazabilidad de cada paso.\n",
    "Incluye una regla específica para eliminar **bullets iniciales** en `ESTABLECIMIENTO`/`DIRECCION` (p. ej., `- IGA`, `-IGA`) sin eliminar guiones internos.\n",
    "\n",
    "## Pasos\n",
    "1. Carga y normalización de **nombres de columnas** (a MAYÚSCULAS)\n",
    "2. Limpieza general (espacios/guiones/vacíos)\n",
    "3. Remoción de bullets iniciales y placeholders\n",
    "4. Normalización de `ESTABLECIMIENTO`, `DIRECCION`, `TELEFONO`\n",
    "5. Estandarización de categóricas\n",
    "6. Clave canónica y **marcado** de posibles duplicados\n",
    "7. Guardado de salidas (CSV limpio, duplicados, bitácora)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a28f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, unicodedata, pandas as pd\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime\n",
    "RAW_PATH = '/mnt/data/establecimientos_diversificado_raw_concat.csv'\n",
    "df = pd.read_csv(RAW_PATH, dtype=str)\n",
    "df.columns = [c.upper() for c in df.columns]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3b2ebb",
   "metadata": {},
   "source": [
    "## Utilidades de normalización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46444899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s: str):\n",
    "    import unicodedata\n",
    "    if not isinstance(s, str): return s\n",
    "    return ''.join(ch for ch in unicodedata.normalize('NFKD', s) if not unicodedata.combining(ch))\n",
    "\n",
    "import re\n",
    "def collapse_spaces_and_hyphens(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    s = s.replace('—', '-').replace('–', '-').replace('−', '-').replace('­', '')\n",
    "    s = re.sub(r'[ \\t\\u00A0]+', ' ', s)\n",
    "    s = re.sub(r'-{2,}', '-', s)\n",
    "    s = re.sub(r'\\s*-\\s*', ' - ', s)\n",
    "    s = re.sub(r'\\s{2,}', ' ', s)\n",
    "    return s.strip()\n",
    "\n",
    "def normalize_text_basic(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    s = s.strip().replace('\"', '').replace('“','').replace('”','').replace('´', \"'\")\n",
    "    s = strip_accents(s).upper()\n",
    "    s = collapse_spaces_and_hyphens(s)\n",
    "    return s\n",
    "\n",
    "def remove_leading_bullets(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    return re.sub(r'^\\s*[-•]+\\s*', '', s)\n",
    "\n",
    "from collections import OrderedDict\n",
    "def expand_address_abbrev(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    txt = ' ' + s + ' '\n",
    "    rules = OrderedDict([\n",
    "        (r'\\bAV[\\.]?\\b', ' AVENIDA '),\n",
    "        (r'\\bAVE[\\.]?\\b', ' AVENIDA '),\n",
    "        (r'\\bAVDA[\\.]?\\b', ' AVENIDA '),\n",
    "        (r'\\bBLVD[\\.]?\\b', ' BOULEVARD '),\n",
    "        (r'\\bCALZ[\\.]?\\b', ' CALZADA '),\n",
    "        (r'\\bCOL[\\.]?\\b', ' COLONIA '),\n",
    "        (r'\\bCOND[\\.]?\\b', ' CONDOMINIO '),\n",
    "        (r'\\bRES[\\.]?\\b', ' RESIDENCIAL '),\n",
    "        (r'\\bZ[\\.]?\\b(?=\\s*\\d)', ' ZONA '),\n",
    "        (r'\\bZONA\\b\\s*(?=\\d)', ' ZONA '),\n",
    "        (r'\\bKM[\\.]?\\b', ' KM '),\n",
    "        (r'\\bNO[\\.]?\\b', ' NUMERO '),\n",
    "        (r'\\bN[\\.]?\\b(?=\\s*\\d)', ' NUMERO '),\n",
    "        (r'\\b#\\b', ' NUMERO '),\n",
    "        (r'\\b2DA\\b', ' 2A '),\n",
    "        (r'\\b3RA\\b', ' 3A '),\n",
    "    ])\n",
    "    for pat, rep in rules.items():\n",
    "        txt = re.sub(pat, rep, txt, flags=re.IGNORECASE)\n",
    "    txt = collapse_spaces_and_hyphens(txt)\n",
    "    return txt\n",
    "\n",
    "def normalize_name(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    s = remove_leading_bullets(s)\n",
    "    s = normalize_text_basic(s)\n",
    "    return s\n",
    "\n",
    "def normalize_address(s: str):\n",
    "    if not isinstance(s, str): return s\n",
    "    s = remove_leading_bullets(s)\n",
    "    s = normalize_text_basic(s)\n",
    "    s = expand_address_abbrev(s)\n",
    "    s = re.sub(r'\\b(\\d+)\\s*\\.\\s*', r'\\1 ', s)\n",
    "    s = re.sub(r'\\bKM\\.\\b', ' KM ', s)\n",
    "    s = collapse_spaces_and_hyphens(s)\n",
    "    return s\n",
    "\n",
    "def clean_phone_field(s: str):\n",
    "    if not isinstance(s, str): return None\n",
    "    nums = re.findall(r'\\d{8}', s)\n",
    "    nums = [n for n in nums if not re.fullmatch(r'0{8}', n)]\n",
    "    seen, unique = set(), []\n",
    "    for n in nums:\n",
    "        if n not in seen:\n",
    "            seen.add(n); unique.append(n)\n",
    "    return ' / '.join(unique) if unique else None\n",
    "\n",
    "def make_duplicate_key(nombre, direccion, municipio, departamento) -> str:\n",
    "    nombre_n = normalize_name(nombre) if isinstance(nombre, str) else ''\n",
    "    direccion_n = normalize_address(direccion) if isinstance(direccion, str) else ''\n",
    "    municipio_n = normalize_text_basic(municipio) if isinstance(municipio, str) else ''\n",
    "    depto_n = normalize_text_basic(departamento) if isinstance(departamento, str) else ''\n",
    "    key = f\"{nombre_n} | {direccion_n} | {municipio_n} | {depto_n}\"\n",
    "    key = collapse_spaces_and_hyphens(key)\n",
    "    return key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabfeb0a",
   "metadata": {},
   "source": [
    "## Pipeline de limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitacora = []\n",
    "def log_step(accion: str, justificacion: str, resumen=None):\n",
    "    bitacora.append({'timestamp': datetime.now().isoformat(timespec='seconds'),\n",
    "                    'accion': accion, 'justificacion': justificacion, 'resumen': resumen or {}})\n",
    "\n",
    "# 1) Limpieza general\n",
    "obj_cols = [c for c in df.columns if df[c].dtype == 'object']\n",
    "df[obj_cols] = df[obj_cols].apply(lambda s: s.map(lambda x: collapse_spaces_and_hyphens(x) if isinstance(x, str) else x))\n",
    "df[obj_cols] = df[obj_cols].replace({'': pd.NA, 'nan': pd.NA, 'None': pd.NA, '-': pd.NA, '--': pd.NA, '—': pd.NA})\n",
    "log_step('normalizar_basico', 'Colapsar espacios/guiones y estandarizar vacíos/guiones simples a NA.')\n",
    "\n",
    "# 2) Backups\n",
    "for col in ['ESTABLECIMIENTO','DIRECCION','TELEFONO']:\n",
    "    if col in df.columns and f'{col}_ORIG' not in df.columns:\n",
    "        df[f'{col}_ORIG'] = df[col]\n",
    "\n",
    "# 3) Bullets/placeholders\n",
    "for col in ['ESTABLECIMIENTO','DIRECCION']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(remove_leading_bullets)\n",
    "import re\n",
    "placeholders = re.compile(r'^[-–—]{1,}$')\n",
    "for col in ['ESTABLECIMIENTO','DIRECCION','TELEFONO','MUNICIPIO','DEPARTAMENTO']:\n",
    "    if col in df.columns:\n",
    "        df.loc[df[col].astype(str).str.fullmatch(placeholders, na=False), col] = pd.NA\n",
    "log_step('bullets_y_placeholders', 'Eliminar bullets iniciales y placeholders de guiones.')\n",
    "\n",
    "# 4) Normalización campos clave\n",
    "if 'ESTABLECIMIENTO' in df.columns:\n",
    "    df['ESTABLECIMIENTO'] = df['ESTABLECIMIENTO'].map(lambda x: normalize_name(x) if isinstance(x, str) else x)\n",
    "if 'DIRECCION' in df.columns:\n",
    "    df['DIRECCION'] = df['DIRECCION'].map(lambda x: normalize_address(x) if isinstance(x, str) else x)\n",
    "if 'TELEFONO' in df.columns:\n",
    "    df['TELEFONO'] = df['TELEFONO'].map(lambda x: clean_phone_field(x) if isinstance(x, str) else x)\n",
    "    df['TELEFONO_VALIDO'] = df['TELEFONO'].apply(lambda x: bool(x) if pd.notna(x) else False)\n",
    "log_step('normalizar_campos_clave', 'Nombre/dirección normalizados; extracción de teléfonos válidos.')\n",
    "\n",
    "# 5) Categóricas\n",
    "for col in ['DEPARTAMENTO','MUNICIPIO','SECTOR','AREA','STATUS','MODALIDAD','JORNADA','PLAN','NIVEL']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(lambda x: normalize_text_basic(x) if isinstance(x, str) else x)\n",
    "log_step('categoricas', 'Estandarizar categóricas a MAYÚSCULAS sin acentos.')\n",
    "\n",
    "# 6) Duplicados\n",
    "for required in ['ESTABLECIMIENTO','DIRECCION','MUNICIPIO','DEPARTAMENTO']:\n",
    "    if required not in df.columns:\n",
    "        df[required] = pd.NA\n",
    "df['CLAVE_DUP'] = df.apply(lambda r: make_duplicate_key(r['ESTABLECIMIENTO'], r['DIRECCION'], r['MUNICIPIO'], r['DEPARTAMENTO']), axis=1)\n",
    "df['POSIBLE_DUPLICADO'] = df.groupby('CLAVE_DUP')['CLAVE_DUP'].transform('size').gt(1)\n",
    "\n",
    "# 7) Guardado\n",
    "CSV_CLEAN = '/mnt/data/establecimientos_diversificado_limpio.csv'\n",
    "CSV_DUPS  = '/mnt/data/posibles_duplicados_nuevo.csv'\n",
    "CSV_LOG   = '/mnt/data/bitacora_limpieza_nueva.csv'\n",
    "df.to_csv(CSV_CLEAN, index=False, encoding='utf-8')\n",
    "df.loc[df['POSIBLE_DUPLICADO'], ['CLAVE_DUP','CODIGO','ESTABLECIMIENTO','DIRECCION','TELEFONO','MUNICIPIO','DEPARTAMENTO','JORNADA','PLAN']]\\\n",
    "  .sort_values(['DEPARTAMENTO','MUNICIPIO','ESTABLECIMIENTO','DIRECCION']).to_csv(CSV_DUPS, index=False, encoding='utf-8')\n",
    "import pandas as pd\n",
    "pd.DataFrame(bitacora).to_csv(CSV_LOG, index=False, encoding='utf-8')\n",
    "CSV_CLEAN, CSV_DUPS, CSV_LOG"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
