{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95b5d425",
   "metadata": {},
   "source": [
    "# Proyecto 1 — Limpieza (v4, completo)\n",
    "**Objetivo:** Limpiar y estandarizar el dataset de establecimientos **NIVEL DIVERSIFICADO** con:\n",
    "- Normalización de textos, espacios y guiones\n",
    "- Extracción y estandarización de **ZONA**\n",
    "- Corrección OCR **solo** en contexto de `RUTA`\n",
    "- **Estandarización de DIRECCION** a formato canónico (`DIRECCION_STD`) con componentes auxiliares\n",
    "- Normalización de **CIUDAD CAPITAL** a `GUATEMALA/GUATEMALA`\n",
    "- Detección de **duplicados en la capital** por posible doble unión (país + capital)\n",
    "- Exportación de resultados y (opcional) código para búsqueda y libro de códigos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c021578e",
   "metadata": {},
   "source": [
    "## 0) Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebc97e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas (ajusta INPUT_CSV si tu archivo se llama distinto o está en otra ruta)\n",
    "INPUT_CSV   = \"establecimientos_diversificado_raw_concat.csv\"\n",
    "CLEAN_CSV   = \"establecimientos_diversificado_limpio_v4.csv\"\n",
    "CAP_CLUSTERS_CSV = \"duplicados_capital_merge_v4.csv\"\n",
    "CAP_DETALLE_CSV  = \"duplicados_capital_merge_detalle_v4.csv\"\n",
    "CODEBOOK_MD = \"Libro_de_Codigos_Proyecto1_v4.md\"  # opcional\n",
    "EXCEL_XLSX  = \"salidas_proyecto1_v4.xlsx\"          # opcional\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306149e6",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea58cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os, unicodedata\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 160)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d455aa",
   "metadata": {},
   "source": [
    "## 2) Carga del CSV consolidado y normalización de nombres de columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fee132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar TODO como texto para no perder ceros a la izquierda ni formatos\n",
    "df = pd.read_csv(INPUT_CSV, dtype=str)\n",
    "# Columnas a MAYÚSCULAS por consistencia\n",
    "df.columns = [c.upper() for c in df.columns]\n",
    "df.shape, df.columns.tolist()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b80cfe",
   "metadata": {},
   "source": [
    "## 3) Utilidades de normalización y parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92542775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_accents(s: str) -> str:\n",
    "    if not isinstance(s, str): return s\n",
    "    return \"\".join(ch for ch in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(ch))\n",
    "\n",
    "\n",
    "def collapse_spaces_and_hyphens(s: str) -> str:\n",
    "    if not isinstance(s, str): return s\n",
    "    s = s.replace(\"—\",\"-\").replace(\"–\",\"-\").replace(\"−\",\"-\").replace(\"­\",\"\")\n",
    "    s = re.sub(r\"[ \\t\\u00A0]+\", \" \", s)\n",
    "    s = re.sub(r\"-{2,}\", \"-\", s)\n",
    "    s = re.sub(r\"\\s*-\\s*\", \" - \", s)\n",
    "    s = re.sub(r\"\\s{2,}\", \" \", s)\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def normalize_text_basic(s: str) -> str:\n",
    "    if not isinstance(s, str): return s\n",
    "    s = s.strip().replace('\"', \"\").replace(\"“\",\"\").replace(\"”\",\"\").replace(\"´\", \"'\")\n",
    "    s = strip_accents(s).upper()\n",
    "    s = collapse_spaces_and_hyphens(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def remove_leading_bullets(s: str) -> str:\n",
    "    if not isinstance(s, str): return s\n",
    "    # Elimina bullets iniciales tipo \"- IGA\", \"-IGA\", \"• NOMBRE\"\n",
    "    return re.sub(r\"^\\s*[-•]+\\s*\", \"\", s)\n",
    "\n",
    "\n",
    "def expand_address_abbrev(s: str) -> str:\n",
    "    \"\"\"Expande abreviaturas frecuentes en direcciones y normaliza separadores.\"\"\"\n",
    "    if not isinstance(s, str): return s\n",
    "    txt = \" \" + s + \" \"\n",
    "    rules = [\n",
    "        (r\"\\bAV[\\.]?\\b\", \" AVENIDA \"), (r\"\\bAVE[\\.]?\\b\", \" AVENIDA \"), (r\"\\bAVDA[\\.]?\\b\", \" AVENIDA \"),\n",
    "        (r\"\\bBLVD[\\.]?\\b\", \" BOULEVARD \"), (r\"\\bCALZ[\\.]?\\b\", \" CALZADA \"),\n",
    "        (r\"\\bCOL[\\.]?\\b\", \" COLONIA \"), (r\"\\bCOND[\\.]?\\b\", \" CONDOMINIO \"), (r\"\\bRES[\\.]?\\b\", \" RESIDENCIAL \"),\n",
    "        (r\"\\bZ[\\.]?\\b(?=\\s*\\d)\", \" ZONA \"), (r\"\\bZONA\\b\\s*(?=\\d)\", \" ZONA \"),\n",
    "        (r\"\\bKM[\\.]?\\b\", \" KM \"), (r\"\\bNO[\\.]?\\b\", \" NUMERO \"), (r\"\\bN[\\.]?\\b(?=\\s*\\d)\", \" NUMERO \"), (r\"\\b#\\b\", \" NUMERO \"),\n",
    "        (r\"\\bEDIF[\\.]?\\b\", \" EDIFICIO \"), (r\"\\bTORRE\\b\", \" TORRE \"),\n",
    "        (r\"\\b2DA\\b\", \" 2A \"), (r\"\\b3RA\\b\", \" 3A \")\n",
    "    ]\n",
    "    for pat, rep in rules:\n",
    "        txt = re.sub(pat, rep, txt, flags=re.IGNORECASE)\n",
    "    txt = collapse_spaces_and_hyphens(txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def normalize_name(s: str) -> str:\n",
    "    if not isinstance(s, str): return s\n",
    "    s = remove_leading_bullets(s)\n",
    "    s = normalize_text_basic(s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def fix_ruta_ocr_general(s: str) -> str:\n",
    "    \"\"\"Corrige errores OCR en contexto de 'RUTA': I/L->1 y O->0 cuando van antes de un dígito.\"\"\"\n",
    "    if not isinstance(s, str): return s\n",
    "    txt = s\n",
    "    txt = re.sub(r\"\\b(RUTA\\s+)[ILil]\\s*(\\d)\\b\", r\"\\g<1>1\\2\", txt)\n",
    "    txt = re.sub(r\"\\b(RUTA\\s+)[Oo]\\s*(\\d)\\b\", r\"\\g<1>0\\2\", txt)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def clean_phone_field(s: str):\n",
    "    \"\"\"Extrae grupos de 8 dígitos válidos; deduplica; retorna unidos por ' / ' o NA.\"\"\"\n",
    "    if not isinstance(s, str): return None\n",
    "    nums = re.findall(r\"\\d{8}\", s)\n",
    "    nums = [n for n in nums if not re.fullmatch(r\"0{8}\", n)]\n",
    "    seen, unique = set(), []\n",
    "    for n in nums:\n",
    "        if n not in seen:\n",
    "            seen.add(n); unique.append(n)\n",
    "    return \" / \".join(unique) if unique else None\n",
    "\n",
    "\n",
    "def extract_zona_token(text: str):\n",
    "    \"\"\"Devuelve 'NN' si encuentra 'ZONA NN' en el texto, si no None.\"\"\"\n",
    "    if not isinstance(text, str): return None\n",
    "    m = re.search(r\"\\bZONA\\s*(\\d{1,2})\\b\", text)\n",
    "    if m:\n",
    "        return (m.group(1).lstrip(\"0\") or \"0\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def parse_address_components(addr: str):\n",
    "    \"\"\"Parsea y estandariza la dirección.\n",
    "    - Expande abreviaturas y corrige OCR (RUTA).\n",
    "    - Extrae ZONA (y la remueve de la dirección).\n",
    "    - Detecta componentes: AVENIDA, CALLE, KM, NUMERO.\n",
    "    - Captura nominativos (COLONIA/RESIDENCIAL/CONDOMINIO/EDIFICIO/TORRE/BARRIO/SECTOR/BOULEVARD/CALZADA/CARRETERA/RUTA).\n",
    "    - Construye DIRECCION_STD: AVENIDA, CALLE, KM, NUMERO, nominativos, resto limpio.\n",
    "    Retorna: (dict_componentes, zona, direccion_std)\n",
    "    \"\"\"\n",
    "    if not isinstance(addr, str) or not addr.strip():\n",
    "        return {}, None, \"\"\n",
    "    a = expand_address_abbrev(normalize_text_basic(addr))\n",
    "    a = fix_ruta_ocr_general(a)\n",
    "    zona = extract_zona_token(a)\n",
    "    a_no_zona = re.sub(r\"\\bZONA\\s*\\d{1,2}\\b\", \"\", a).strip()\n",
    "    a_no_zona = collapse_spaces_and_hyphens(a_no_zona)\n",
    "\n",
    "    comp = {}\n",
    "    # AVENIDA ('AVENIDA 7A' o '7A AVENIDA')\n",
    "    m = re.search(r\"\\bAVENIDA\\s+([0-9]{1,2}[A-Z]?)\\b\", a_no_zona) or re.search(r\"\\b([0-9]{1,2}[A-Z]?)\\s+AVENIDA\\b\", a_no_zona)\n",
    "    if m: comp[\"AVENIDA\"] = m.group(1)\n",
    "\n",
    "    # CALLE ('CALLE 5' o '5 CALLE')\n",
    "    m = re.search(r\"\\bCALLE\\s+([0-9]{1,2}[A-Z]?)\\b\", a_no_zona) or re.search(r\"\\b([0-9]{1,2}[A-Z]?)\\s+CALLE\\b\", a_no_zona)\n",
    "    if m: comp[\"CALLE\"] = m.group(1)\n",
    "\n",
    "    # KM\n",
    "    m = re.search(r\"\\bKM\\s*([0-9]+(?:\\.[0-9]+)?)\\b\", a_no_zona)\n",
    "    if m: comp[\"KM\"] = m.group(1)\n",
    "\n",
    "    # NUMERO\n",
    "    m = re.search(r\"\\bNUMERO\\s*([0-9A-Z\\-\\/]+)\\b\", a_no_zona)\n",
    "    if m: comp[\"NUMERO\"] = m.group(1)\n",
    "\n",
    "    # NOMINATIVOS\n",
    "    nominativos = [\"COLONIA\",\"RESIDENCIAL\",\"CONDOMINIO\",\"EDIFICIO\",\"TORRE\",\"BARRIO\",\"SECTOR\",\"BOULEVARD\",\"CALZADA\",\"CARRETERA\",\"RUTA\"]\n",
    "    nom_found = []\n",
    "    rem = a_no_zona\n",
    "    for key in nominativos:\n",
    "        m = re.search(rf\"\\b{key}\\b\\s*([A-Z0-9\\-\\.\\s]+)\", rem)\n",
    "        if m:\n",
    "            val = m.group(1).strip()\n",
    "            for stop in nominativos + [\"AVENIDA\",\"CALLE\",\"KM\",\"NUMERO\"]:\n",
    "                val = re.split(rf\"\\b{stop}\\b\", val)[0]\n",
    "            val = val.strip(\" ,.;-\")\n",
    "            if val:\n",
    "                nom_found.append(f\"{key} {val}\")\n",
    "                rem = re.sub(rf\"\\b{key}\\b\\s*[A-Z0-9\\-\\.\\s]+\", \"\", rem, count=1).strip()\n",
    "\n",
    "    parts = []\n",
    "    if \"AVENIDA\" in comp: parts.append(f\"AVENIDA {comp['AVENIDA']}\")\n",
    "    if \"CALLE\"   in comp: parts.append(f\"CALLE {comp['CALLE']}\")\n",
    "    if \"KM\"      in comp: parts.append(f\"KM {comp['KM']}\")\n",
    "    if \"NUMERO\"  in comp: parts.append(f\"NUMERO {comp['NUMERO']}\")\n",
    "    if nom_found: parts.extend(nom_found)\n",
    "\n",
    "    resto = rem.strip(\",; \")\n",
    "    resto = collapse_spaces_and_hyphens(resto)\n",
    "    for p in parts + ([f\"ZONA {zona}\"] if zona else []):\n",
    "        if p:\n",
    "            resto = re.sub(re.escape(p), \"\", resto).strip(\",; \")\n",
    "    direccion_std = \", \".join([p for p in parts if p]) if parts else a_no_zona\n",
    "    if resto and resto not in direccion_std:\n",
    "        direccion_std = \", \".join([direccion_std, resto]) if direccion_std else resto\n",
    "    direccion_std = collapse_spaces_and_hyphens(direccion_std)\n",
    "    direccion_std = re.sub(r\"\\s{2,}\", \" \", direccion_std).strip(\" ,\")\n",
    "\n",
    "    return comp, zona, direccion_std\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122521e2",
   "metadata": {},
   "source": [
    "## 4) Limpieza básica + respaldos + categóricas + teléfono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada63c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colapsar espacios/guiones en todas las columnas de texto\n",
    "obj_cols = [c for c in df.columns if df[c].dtype == \"object\"]\n",
    "df[obj_cols] = df[obj_cols].apply(lambda s: s.map(lambda x: collapse_spaces_and_hyphens(x) if isinstance(x, str) else x))\n",
    "\n",
    "# Estandarizar vacíos/guiones de relleno a NA\n",
    "df[obj_cols] = df[obj_cols].replace({\n",
    "    \"\": pd.NA, \"nan\": pd.NA, \"None\": pd.NA, \"-\": pd.NA, \"--\": pd.NA, \"—\": pd.NA\n",
    "})\n",
    "\n",
    "# Respaldos de originales (si no existen)\n",
    "for col in [\"ESTABLECIMIENTO\",\"DIRECCION\",\"TELEFONO\"]:\n",
    "    if col in df.columns and f\"{col}_ORIG\" not in df.columns:\n",
    "        df[f\"{col}_ORIG\"] = df[col]\n",
    "\n",
    "# Remover bullets iniciales\n",
    "for col in [\"ESTABLECIMIENTO\",\"DIRECCION\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(remove_leading_bullets)\n",
    "\n",
    "# Normalizar nombre de establecimiento\n",
    "if \"ESTABLECIMIENTO\" in df.columns:\n",
    "    df[\"ESTABLECIMIENTO\"] = df[\"ESTABLECIMIENTO\"].map(normalize_name)\n",
    "\n",
    "# Teléfono: extraer 8 dígitos, deduplicar y unir por \" / \"\n",
    "if \"TELEFONO\" in df.columns:\n",
    "    df[\"TELEFONO\"] = df[\"TELEFONO\"].map(clean_phone_field)\n",
    "    df[\"TELEFONO_VALIDO\"] = df[\"TELEFONO\"].apply(lambda x: bool(x) if pd.notna(x) else False)\n",
    "\n",
    "# Categóricas a MAYÚSCULAS sin acentos\n",
    "for col in [\"DEPARTAMENTO\",\"MUNICIPIO\",\"SECTOR\",\"AREA\",\"STATUS\",\"MODALIDAD\",\"JORNADA\",\"PLAN\",\"NIVEL\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].map(lambda x: normalize_text_basic(x) if isinstance(x, str) else x)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27306492",
   "metadata": {},
   "source": [
    "## 5) Dirección: extracción de ZONA y `DIRECCION_STD` canónica + componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234462ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_avenida, dir_calle, dir_km, dir_numero = [], [], [], []\n",
    "zonas, dir_std_list = [], []\n",
    "\n",
    "for val in df[\"DIRECCION\"].fillna(\"\").astype(str):\n",
    "    comp, zona, dstd = parse_address_components(val)\n",
    "    dir_std_list.append(dstd if dstd else pd.NA)\n",
    "    zonas.append(zona if zona is not None else pd.NA)\n",
    "    dir_avenida.append(comp.get(\"AVENIDA\", pd.NA))\n",
    "    dir_calle.append(comp.get(\"CALLE\", pd.NA))\n",
    "    dir_km.append(comp.get(\"KM\", pd.NA))\n",
    "    dir_numero.append(comp.get(\"NUMERO\", pd.NA))\n",
    "\n",
    "# Crear/llenar ZONA\n",
    "if \"ZONA\" not in df.columns:\n",
    "    df[\"ZONA\"] = pd.NA\n",
    "df[\"ZONA\"] = df[\"ZONA\"].fillna(pd.Series(zonas))\n",
    "\n",
    "# Dirección estandarizada + columnas auxiliares\n",
    "df[\"DIRECCION_STD\"] = dir_std_list\n",
    "df[\"DIR_AVENIDA\"] = dir_avenida\n",
    "df[\"DIR_CALLE\"]   = dir_calle\n",
    "df[\"DIR_KM\"]      = dir_km\n",
    "df[\"DIR_NUMERO\"]  = dir_numero\n",
    "\n",
    "# Asegurar formato final normalizado\n",
    "df[\"DIRECCION_STD\"] = df[\"DIRECCION_STD\"].map(normalize_text_basic)\n",
    "\n",
    "df[[\"DIRECCION\",\"DIRECCION_STD\",\"ZONA\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b37e23",
   "metadata": {},
   "source": [
    "## 6) Normalización de 'CIUDAD CAPITAL' y zonas en DEPARTAMENTO/MUNICIPIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10007bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_capital_and_zone_row(row):\n",
    "    dept = str(row.get(\"DEPARTAMENTO\", \"\") or \"\")\n",
    "    muni = str(row.get(\"MUNICIPIO\", \"\") or \"\")\n",
    "    # Detecta CIUDAD CAPITAL\n",
    "    is_capital = bool(re.search(r\"\\bCIUDAD\\s+CAPITAL\\b\", dept) or re.search(r\"\\bCIUDAD\\s+CAPITAL\\b\", muni))\n",
    "    # Extrae zona si está mal ubicada\n",
    "    z_depto = extract_zona_token(dept)\n",
    "    z_muni  = extract_zona_token(muni)\n",
    "    zona = row.get(\"ZONA\", pd.NA)\n",
    "    zona = zona if pd.notna(zona) else (z_depto or z_muni)\n",
    "    if is_capital or z_depto is not None or z_muni is not None:\n",
    "        row[\"DEPARTAMENTO\"] = \"GUATEMALA\"\n",
    "        row[\"MUNICIPIO\"] = \"GUATEMALA\"\n",
    "        row[\"ZONA\"] = zona\n",
    "    return row\n",
    "\n",
    "df = df.apply(normalize_capital_and_zone_row, axis=1)\n",
    "# Estandarizar NA en ZONA\n",
    "df[\"ZONA\"] = df[\"ZONA\"].where(df[\"ZONA\"].notna() & df[\"ZONA\"].astype(str).str.strip().ne(\"\"), pd.NA)\n",
    "\n",
    "df[[\"DEPARTAMENTO\",\"MUNICIPIO\",\"ZONA\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f26214c",
   "metadata": {},
   "source": [
    "## 7) Duplicados en Ciudad de Guatemala (posible doble unión país + capital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227de4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm(s): return normalize_text_basic(s) if isinstance(s, str) else \"\"\n",
    "\n",
    "# Clave normalizada para detectar duplicados de capital (usa DIRECCION_STD)\n",
    "df[\"__KEY_MERGE_CAP__\"] = df.apply(lambda r: \"|\".join([\n",
    "    _norm(r.get(\"ESTABLECIMIENTO\",\"\")),\n",
    "    _norm(r.get(\"DIRECCION_STD\",\"\")),\n",
    "    _norm(r.get(\"MUNICIPIO\",\"\")),\n",
    "    _norm(r.get(\"DEPARTAMENTO\",\"\")),\n",
    "    _norm(r.get(\"JORNADA\",\"\")),\n",
    "    _norm(r.get(\"PLAN\",\"\")),\n",
    "    _norm(r.get(\"TELEFONO\",\"\")),\n",
    "]), axis=1)\n",
    "\n",
    "mask_capital = (df[\"DEPARTAMENTO\"]==\"GUATEMALA\") & (df[\"MUNICIPIO\"]==\"GUATEMALA\")\n",
    "grp_sizes = df[mask_capital].groupby(\"__KEY_MERGE_CAP__\")[\"__KEY_MERGE_CAP__\"].transform(\"size\")\n",
    "\n",
    "df[\"DUP_CAPITAL_MERGE\"] = False\n",
    "df.loc[mask_capital & grp_sizes.gt(1), \"DUP_CAPITAL_MERGE\"] = True\n",
    "\n",
    "# Marca si dentro del cluster hay CODIGOS distintos\n",
    "dup_cap_groups = df.loc[df[\"DUP_CAPITAL_MERGE\"]].groupby(\"__KEY_MERGE_CAP__\")\n",
    "key_has_diff_codes = dup_cap_groups[\"CODIGO\"].apply(lambda s: len(set(s.dropna().astype(str))) > 1)\n",
    "key_has_diff_codes = key_has_diff_codes.reindex(df[\"__KEY_MERGE_CAP__\"]).fillna(False).values\n",
    "df[\"DUP_CAPITAL_CODIGOS_DISTINTOS\"] = key_has_diff_codes\n",
    "\n",
    "\n",
    "df.loc[df[\"DUP_CAPITAL_MERGE\"], [\"ESTABLECIMIENTO\",\"DIRECCION_STD\",\"ZONA\",\"MUNICIPIO\",\"DEPARTAMENTO\",\"JORNADA\",\"PLAN\",\"CODIGO\",\"DUP_CAPITAL_CODIGOS_DISTINTOS\"]].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffc4f87",
   "metadata": {},
   "source": [
    "## 8) Guardar CSVs de salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469ec2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset limpio v4\n",
    "df.to_csv(CLEAN_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Tablas de duplicados en capital (clusters y detalle)\n",
    "cap_dups = df.loc[df[\"DUP_CAPITAL_MERGE\"], [\"__KEY_MERGE_CAP__\",\"CODIGO\",\"ESTABLECIMIENTO\",\"DIRECCION_STD\",\"ZONA\",\"TELEFONO\",\"JORNADA\",\"PLAN\",\"MUNICIPIO\",\"DEPARTAMENTO\",\"DUP_CAPITAL_CODIGOS_DISTINTOS\"]]\n",
    "\n",
    "cluster_rows = []\n",
    "for key, sub in cap_dups.groupby(\"__KEY_MERGE_CAP__\"):\n",
    "    cods = sorted(set(sub[\"CODIGO\"].dropna().astype(str)))\n",
    "    cluster_rows.append({\n",
    "        \"KEY\": key,\n",
    "        \"ESTABLECIMIENTO\": sub[\"ESTABLECIMIENTO\"].iloc[0],\n",
    "        \"DIRECCION_STD\": sub[\"DIRECCION_STD\"].iloc[0],\n",
    "        \"ZONA\": sub[\"ZONA\"].iloc[0],\n",
    "        \"JORNADA\": sub[\"JORNADA\"].iloc[0],\n",
    "        \"PLAN\": sub[\"PLAN\"].iloc[0],\n",
    "        \"TELEFONO\": sub[\"TELEFONO\"].iloc[0],\n",
    "        \"MUNICIPIO\": sub[\"MUNICIPIO\"].iloc[0],\n",
    "        \"DEPARTAMENTO\": sub[\"DEPARTAMENTO\"].iloc[0],\n",
    "        \"N_FILAS\": len(sub),\n",
    "        \"CODIGOS\": \" | \".join(cods),\n",
    "        \"CODIGOS_DISTINTOS\": (len(cods) > 1)\n",
    "    })\n",
    "cap_clusters = pd.DataFrame(cluster_rows).sort_values([\"ESTABLECIMIENTO\",\"ZONA\",\"DIRECCION_STD\",\"JORNADA\",\"PLAN\"])\n",
    "\n",
    "cap_clusters.to_csv(CAP_CLUSTERS_CSV, index=False, encoding=\"utf-8\")\n",
    "cap_dups.drop(columns=[\"__KEY_MERGE_CAP__\"]).to_csv(CAP_DETALLE_CSV, index=False, encoding=\"utf-8\")\n",
    "\n",
    "CLEAN_CSV, CAP_CLUSTERS_CSV, CAP_DETALLE_CSV, cap_clusters.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9be848",
   "metadata": {},
   "source": [
    "## 9) (Opcional) Función de búsqueda rápida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6849b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _norm_q(s):\n",
    "    if not isinstance(s, str): return \"\"\n",
    "    s = s.strip().upper()\n",
    "    s = \"\".join(ch for ch in unicodedata.normalize(\"NFKD\", s) if not unicodedata.combining(ch))\n",
    "    s = re.sub(r\"\\s*-\\s*\", \" - \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def buscar(df, nombre=None, municipio=None, departamento=None, zona=None):\n",
    "    m = pd.Series(True, index=df.index)\n",
    "    if nombre:\n",
    "        m &= df[\"ESTABLECIMIENTO\"].fillna(\"\").map(_norm_q).str.contains(re.escape(_norm_q(nombre)), regex=True, na=False)\n",
    "    if municipio:\n",
    "        m &= df[\"MUNICIPIO\"].fillna(\"\").map(_norm_q).str.contains(re.escape(_norm_q(municipio)), regex=True, na=False)\n",
    "    if departamento:\n",
    "        m &= df[\"DEPARTAMENTO\"].fillna(\"\").map(_norm_q).str.contains(re.escape(_norm_q(departamento)), regex=True, na=False)\n",
    "    if zona is not None:\n",
    "        m &= df[\"ZONA\"].astype(str).fillna(\"\").eq(str(zona))\n",
    "    cols = [\"CODIGO\",\"ESTABLECIMIENTO\",\"DIRECCION\",\"DIRECCION_STD\",\"ZONA\",\"MUNICIPIO\",\"DEPARTAMENTO\",\"JORNADA\",\"PLAN\",\n",
    "            \"TELEFONO\",\"DUP_CAPITAL_MERGE\",\"DUP_CAPITAL_CODIGOS_DISTINTOS\"]\n",
    "    cols = [c for c in cols if c in df.columns]\n",
    "    return df.loc[m, cols].sort_values([\"DEPARTAMENTO\",\"MUNICIPIO\",\"ESTABLECIMIENTO\",\"DIRECCION_STD\"]).reset_index(drop=True)\n",
    "\n",
    "# Ejemplos:\n",
    "# buscar(df, nombre=\"IGA\", municipio=\"GUATEMALA\")\n",
    "# buscar(df, nombre=\"IGA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e614a86",
   "metadata": {},
   "source": [
    "## 10) (Opcional) Exportar a Excel (múltiples hojas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af609c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(EXCEL_XLSX, engine=\"xlsxwriter\") as writer:\n",
    "    df.to_excel(writer, index=False, sheet_name=\"LIMPIO_V4\")\n",
    "    if os.path.exists(CAP_CLUSTERS_CSV):\n",
    "        pd.read_csv(CAP_CLUSTERS_CSV, dtype=str).to_excel(writer, index=False, sheet_name=\"DUPS_CAPITAL_CLUSTERS\")\n",
    "    if os.path.exists(CAP_DETALLE_CSV):\n",
    "        pd.read_csv(CAP_DETALLE_CSV, dtype=str).to_excel(writer, index=False, sheet_name=\"DUPS_CAPITAL_DETALLE\")\n",
    "EXCEL_XLSX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316d6333",
   "metadata": {},
   "source": [
    "## 11) (Opcional) Generar Libro de Códigos (Markdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73536366",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "lines.append(\"# Libro de Códigos – Establecimientos (Diversificado, v4)\\n\")\n",
    "lines.append(\"**Estándares de limpieza aplicados:**\\n\")\n",
    "lines.append(\"- Texto en MAYÚSCULAS y SIN ACENTOS en campos categóricos.\\n\")\n",
    "lines.append(\"- Guiones internos conservados con espacios estándar (` - `).\\n\")\n",
    "lines.append(\"- Bullets iniciales removidos en `ESTABLECIMIENTO`/`DIRECCION`.\\n\")\n",
    "lines.append(\"- `DIRECCION`: abreviaturas expandidas; OCR en `RUTA` (I/L→1, O→0).\\n\")\n",
    "lines.append(\"- `ZONA`: extraída de dirección y/o dept/muni; `CIUDAD CAPITAL` → `GUATEMALA/GUATEMALA`.\\n\")\n",
    "lines.append(\"- `DIRECCION_STD` con orden canónico: AVENIDA, CALLE, KM, NUMERO, nominativos, resto.\\n\")\n",
    "lines.append(\"- Duplicados en capital por posible doble unión (`DUP_CAPITAL_MERGE`, `DUP_CAPITAL_CODIGOS_DISTINTOS`).\\n\")\n",
    "lines.append(\"- Sin eliminación de filas/columnas; solo marcado/normalización.\\n\")\n",
    "\n",
    "lines.append(\"\\n**Descripción general:**\\n\")\n",
    "lines.append(f\"- Registros: {len(df)}\\n\")\n",
    "lines.append(f\"- ZONA con valor: {int(df['ZONA'].notna().sum())} | NA: {int(df['ZONA'].isna().sum())}\\n\")\n",
    "lines.append(\"- Archivos: `duplicados_capital_merge_v4.csv`, `duplicados_capital_merge_detalle_v4.csv`.\\n\")\n",
    "\n",
    "lines.append(\"\\n## Variables\\n\")\n",
    "for col in df.columns:\n",
    "    ejemplo = df[col].dropna().astype(str).head(3).tolist()\n",
    "    ejemplo = [e[:120] for e in ejemplo]\n",
    "    desc = \"\"\n",
    "    if col == \"ESTABLECIMIENTO_ORIG\": desc = \"Valor original del nombre (antes de limpieza).\"\n",
    "    elif col == \"DIRECCION_ORIG\": desc = \"Valor original de la dirección (antes de limpieza).\"\n",
    "    elif col == \"TELEFONO_ORIG\": desc = \"Valor original del teléfono (antes de extracción).\"\n",
    "    elif col == \"TELEFONO_VALIDO\": desc = \"Indicador: True si se extrajo al menos un teléfono de 8 dígitos.\"\n",
    "    elif col == \"DIRECCION_STD\": desc = \"Dirección estandarizada (orden canónico).\"\n",
    "    elif col in {\"DIR_AVENIDA\",\"DIR_CALLE\",\"DIR_KM\",\"DIR_NUMERO\"}: desc = \"Componente extraído de la dirección.\"\n",
    "    elif col == \"ZONA\": desc = \"Zona administrativa (si aplica); NA si no disponible.\"\n",
    "    elif col in {\"DEPARTAMENTO\",\"MUNICIPIO\"}: desc = \"Ubicación administrativa normalizada.\"\n",
    "    elif col == \"DUP_CAPITAL_MERGE\": desc = \"True si el registro forma parte de un cluster duplicado en la capital (posible doble unión).\"\n",
    "    elif col == \"DUP_CAPITAL_CODIGOS_DISTINTOS\": desc = \"True si dentro de su cluster hay códigos distintos.\"\n",
    "    else: desc = \"Campo de la fuente; normalizado cuando aplica.\"\n",
    "    lines.append(f\"### {col}\\n- **Descripción:** {desc}\\n- **Ejemplo(s):** {', '.join(ejemplo) if ejemplo else '—'}\\n\")\n",
    "\n",
    "with open(CODEBOOK_MD, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"\\n\".join(lines))\n",
    "\n",
    "CODEBOOK_MD"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
